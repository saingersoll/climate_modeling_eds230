---
title: "sensitivity_LHS"
output: html_document
date: '2022-04-19'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(sensitivity)
library(tidyverse)
library(lhs)
library(purrr)
```

# Example of using Latin Hypercube sampling for sensitivity analysis

Lets look at our almond yield example

```{r LHS}
# for formal sensitivity analysis it is useful to describe output in
# several summary statistics - how about mean, max and min yield
source("../R/compute_almond_yield.R")


# set a random seed to make things 'random'
set.seed(1)

# which parameters
pnames = c("Tmincoeff1", "Tmincoeff2", "Pcoeff1", "Pcoeff2", "intercep")

# how many parameters
npar =  length(pnames)
# how many samples
nsample = 100

# mapping parameter distribution between 0 and 1
parm_quant = randomLHS(nsample, npar)
colnames(parm_quant)=pnames
# choose distributions for parameters - this would come from
# what you know about the likely range of variation
# then use our random samples to pick the quantiles

parm = as.data.frame(matrix(nrow=nrow(parm_quant), ncol=ncol(parm_quant)))
colnames(parm) = pnames
# for each parameter pick samples 
# I'm using several examples normal distribution (with 10% standard deviation) and uniform with +- 10%
# in reality I should pick distribution from knowledge about uncertainty in parameters

# to make it easy to change i'm setting standard deviation / range variation to a variable
pvar = 10

parm[,"Tmincoeff1"] = qnorm(parm_quant[,"Tmincoeff1"], mean=-0.015, sd=0.015/pvar)
parm[,"Tmincoeff2"] = qnorm(parm_quant[,"Tmincoeff2"], mean=-0.0046, sd=0.0046/pvar)

# for uniform I'm using +- 10%
parm[,"Pcoeff1"] = qunif(parm_quant[,"Pcoeff1"], min=-0.07-0.07/pvar, max=-0.07+0.07/pvar)
parm[,"Pcoeff2"] = qunif(parm_quant[,"Pcoeff2"], min=-0.0043-0.0043/pvar, max=-0.0043+0.0043/pvar)

parm[,"intercep"] = qnorm(parm_quant[,"intercep"], mean=0.28, sd=0.28/pvar)
# note I could also index by column number by names keep things more clear, fewer mistakes
#parm[,5] = qnorm(parm_quant[,5], mean=0.28, sd=0.28/pvar)

head(parm)
```

# Run model for parameter sets

* We will do this in R

* We can use **pmap** to efficiently run our model for all of our parameter sets

but first

# Examining Output

Sensitivity of What?

If your model is estimating a single value, you are done

* long term mean almond yield anomoly
*  mean profit from solar

But models are often estimating multiple values

* streamflow
* almond yield anomoly for multiple years
  
In that case to quantify sensitivity you need summary metrics

* mean
* max
* min
* variance

Which one depends on what you care about


```{r almondsens}
# read in the input data
SB=read.table("clim.txt", header=T)
clim= SB



# lets now run our model for all of the parameters generated by LHS
# pmap is useful here - it is a map function that uses the actual names of input parameters

yields = parm %>% pmap(compute_almond_yield,clim=clim)

# notice that what pmap returns is a list 
head(yields)

# turn results in to a dataframe for easy display/analysis
yieldsd = yields %>% map_dfr(`[`,c("maxyield","minyield","meanyield"))


```


#  Plotting 

Plot relationship between parameter and output
to understand how uncertainty in parameter impacts the output to determine over what ranges of the parameter uncertainty is most important (biggest effect)


* Use a box plot (of output)
to graphically show the impact of uncertainty on output of interest

* To see more of the distribution - graph the cumulative distribution
  * high slope, many values in that range
  * low slope, few values in that range
  * constant slope, even distribution
  
* Scatterplots against parameter values

---

```{r senplot}



# add uncertainty bounds on our estimates
tmp = yieldsd %>% gather(value="value", key="yield")
ggplot(tmp, aes(yield, value, col=yield))+geom_boxplot()+
  labs(y="Yield (as anomoly)")

# note that you don't see the ranges because of the scale (min yield anomoly much smaller than max) - here's a more informative way to graph
ggplot(tmp, aes(yield, value, col=yield))+
  geom_boxplot()+labs(y="Yield (as anomoly)")+
  facet_wrap(~yield, scales="free" )


# cumulative distribution
ggplot(yieldsd, aes(maxyield))+stat_ecdf()


# plot parameter sensitivity
# a bit tricky but nice way to make it easy to plot all parameters against all values
tmp = cbind.data.frame(yieldsd, parm)
tmp2 = tmp %>% gather(maxyield, minyield, meanyield, value="yvalue",key="yieldtype")
tmp3 = tmp2 %>% gather(-yvalue, -yieldtype, key="parm", value="parmvalue")
ggplot(tmp3, aes(parmvalue, yvalue, col=yieldtype))+geom_point()+facet_wrap(~yieldtype*parm, scales="free", ncol=5)

```

Quantifying

# Correlation and Pcc for Maximum Yield
```{r quantifying}
# combine parameter sets with output


# simple correlation coefficients
result = map(parm, cor.test, y=yieldsd$maxyield)
result$Tmincoeff1
result$Tmincoeff2
result$Pcoeff1
result$Pcoeff2
result$intercep

# just the confidence interval
justconf = result %>% map_df("conf.int")
justconf

# partial regression rank coefficients

senresult_rank = pcc(parm, yieldsd$maxyield, rank=TRUE )
senresult_rank
plot(senresult_rank)


```
